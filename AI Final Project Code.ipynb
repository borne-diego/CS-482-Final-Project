{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mushroom Poison Classification**"
      ],
      "metadata": {
        "id": "bExlBPq86Etx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Set Up**"
      ],
      "metadata": {
        "id": "V2hTFVZc6HJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import dataset.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Fetch dataset.\n",
        "mushroom = pd.read_csv('mushroom_cleaned.csv')\n",
        "\n",
        "X = mushroom.drop(columns=['class'])\n",
        "y = mushroom['class']\n",
        "\n",
        "# Normalize data.\n",
        "X = normalize(X, norm='max')\n",
        "\n",
        "# Partition data into test and train sets.\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=.4)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=.5)\n",
        "\n",
        "# Create tensors for neural network\n",
        "X_train_tensor = torch.from_numpy(X_train)\n",
        "X_test_tensor = torch.from_numpy(X_test)\n",
        "X_val_tensor = torch.from_numpy(X_val)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train.values)\n",
        "y_test_tensor = torch.tensor(y_test.values)\n",
        "y_val_tensor = torch.tensor(y_val.values)\n",
        "\n",
        "# Create DMatrix objects for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)"
      ],
      "metadata": {
        "id": "ztvKP5iK_SDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost**"
      ],
      "metadata": {
        "id": "-Ex75o1p6KIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining parameters for XGBoost\n",
        "params = {\n",
        "  'objective': 'binary:hinge',\n",
        "  'eval_metric': ['error', 'logloss'],\n",
        "}\n",
        "\n",
        "evallist = [(dtrain, 'train'), (dval, 'eval')]\n",
        "\n",
        "num_round = 250\n",
        "\n",
        "evals_result = {}\n",
        "\n",
        "# Training model\n",
        "bst = xgb.train(params, dtrain, num_round, evallist, evals_result=evals_result, verbose_eval=False)\n",
        "\n",
        "# Testing model on training and test sets\n",
        "predictions_train = bst.predict(dtrain)\n",
        "predictions_val = bst.predict(dval)\n",
        "predictions_test = bst.predict(dtest)\n",
        "\n",
        "xgb_train_accuracy = accuracy_score(y_train, predictions_train)\n",
        "xgb_val_accuracy = accuracy_score(y_val, predictions_val)\n",
        "xgb_test_accuracy = accuracy_score(y_test, predictions_test)\n",
        "\n",
        "xgb_stats = precision_recall_fscore_support(y_test, predictions_test, average='macro')\n",
        "\n",
        "# Convert error to accuracy\n",
        "train_accuracy = list(map(lambda x: 1-x, evals_result['train']['error']))\n",
        "eval_accuracy = list(map(lambda x: 1-x, evals_result['eval']['error']))\n",
        "\n",
        "# Plot results\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].set_title(\"Accuracy Results\")\n",
        "ax[0].plot(train_accuracy, label='Training Accuracy')\n",
        "ax[0].plot(eval_accuracy, label='Validation Accuracy')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].set_title(\"Loss Results\")\n",
        "ax[1].plot(evals_result['train']['logloss'], label='Training Loss')\n",
        "ax[1].plot(evals_result['eval']['logloss'], label='Validation Loss')\n",
        "ax[1].legend()\n",
        "fig.set_size_inches(9, 5)\n",
        "ax[1].grid(True, color='lightgray', linestyle='--', linewidth=0.5)\n",
        "ax[1].spines[['right', 'top']].set_visible(False)\n",
        "ax[0].grid(True, color='lightgray', linestyle='--', linewidth=0.5)\n",
        "ax[0].spines[['right', 'top']].set_visible(False)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "6WBMIpHH6Lw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Allowing user input to test model\n",
        "user_input = []\n",
        "user_input.append(int(input(\"Enter cap diameter(cm):\\n\")))\n",
        "user_input.append(int(input(\"Enter cap shape(bell=1, conical=2, convex=3, flat=4, sunken=5, spherical=6, others=7):\\n\")))\n",
        "user_input.append(int(input(\"Enter gill attachment(adnate=1, adnexed=2, decurrent=3, free=4, sinuate=5, pores=6, none=7, unknown=8):\\n\")))\n",
        "user_input.append(int(input(\"Enter gill color(brown=1, buff=2, gray=3, green=4, pink=5, purple=6, red=7, white=8, yellow=9, blue=10, orange=11, black=12, none=13):\\n\")))\n",
        "user_input.append(int(input(\"Enter stem height(mm):\\n\")))\n",
        "user_input.append(int(input(\"Enter stem width(cm):\\n\")))\n",
        "user_input.append(int(input(\"Enter stem color(brown=1, buff=2, gray=3, green=4, pink=5, purple=6, red=7, white=8, yellow=9, blue=10, orange=11, black=12, none=13):\\n\")))\n",
        "user_input.append(int(input(\"Enter season(spring=1, summer=2, autumn=3, winter=4):\\n\")))\n",
        "\n",
        "user_input = np.array(user_input).reshape(1, -1)\n",
        "user_input = normalize(user_input, norm='max')\n",
        "user_dmatrix = xgb.DMatrix(user_input)\n",
        "\n",
        "result = bst.predict(user_dmatrix)\n",
        "\n",
        "if(result == 1):\n",
        "  print(\"Mushroom is poisonous.\")\n",
        "else:\n",
        "  print(\"Mushroom is edible.\")"
      ],
      "metadata": {
        "id": "4N4GDIU_8m31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network**\n"
      ],
      "metadata": {
        "id": "ymnuJwRN6MN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "# Define neural network\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define each step of custom network for use in forward()\n",
        "        self.fc1 = nn.Linear(input_size, 16)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(16, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(32, 16)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc5 = nn.Linear(16, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = None\n",
        "\n",
        "        # Define forwards pass using each step defined in __init__()\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.relu4(out)\n",
        "        out = self.fc5(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "1fCySvz16MHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the network\n",
        "def train_network(model,optimizer,criterion,X_train_tensor,y_train_tensor,X_val_tensor,y_val_tensor,num_epochs,train_losses,val_losses):\n",
        "  ygraph = []\n",
        "  xgraph = []\n",
        "  for epoch in range(num_epochs):\n",
        "    # using training data to train\n",
        "    optimizer.zero_grad()\n",
        "    z = model(X_train_tensor)\n",
        "    loss = criterion(z, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses[epoch] = loss\n",
        "\n",
        "    # using training data to see accuracy\n",
        "    with torch.no_grad():\n",
        "      xgraph.append(get_accuracy_multiclass(model(X_train_tensor), y_train_tensor))\n",
        "\n",
        "    # using validation data to see losses and accuracy\n",
        "    with torch.no_grad():\n",
        "      optimizer.zero_grad()\n",
        "      z = model(X_val_tensor)\n",
        "      loss = criterion(z, y_val_tensor)\n",
        "      val_losses[epoch] = loss\n",
        "      ygraph.append(get_accuracy_multiclass(model(X_val_tensor), y_val_tensor))\n",
        "\n",
        "  # Graphing train and validation results\n",
        "  plt.plot(np.arange(1, num_epochs + 1), ygraph, color=\"r\", label=\"testing\")\n",
        "  plt.plot(np.arange(1, num_epochs + 1), xgraph, color=\"orange\", label=\"validation\")\n",
        "  plt.title(\"Train and Test Accuracy Over Epochs\")\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.grid(True, color='lightgray', linestyle='--', linewidth=0.5)\n",
        "  plt.gca().spines[['right', 'top']].set_visible(False)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "iJYsyRr6J810"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for calculating multiclass accuracy\n",
        "def get_accuracy_multiclass(pred_arr,original_arr):\n",
        "    if len(pred_arr)!=len(original_arr):\n",
        "        return False\n",
        "    pred_arr = pred_arr.numpy()\n",
        "    original_arr = original_arr.numpy()\n",
        "    final_pred= []\n",
        "    for i in range(len(pred_arr)):\n",
        "        final_pred.append(np.argmax(pred_arr[i]))\n",
        "    final_pred = np.array(final_pred)\n",
        "    count = 0\n",
        "    for i in range(len(original_arr)):\n",
        "        if final_pred[i] == original_arr[i]:\n",
        "            count+=1\n",
        "    return count/len(final_pred)"
      ],
      "metadata": {
        "id": "mSfk0E01J9G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training network\n",
        "learning_rate = 0.01\n",
        "loss = torch.nn.functional.cross_entropy\n",
        "input_dim  = 8\n",
        "output_dim = 2\n",
        "nn = NeuralNet(input_dim, output_dim)\n",
        "optimizer = torch.optim.Adam(nn.parameters(), lr=learning_rate)\n",
        "num_epochs = 6000\n",
        "train_losses = np.zeros(num_epochs)\n",
        "test_losses  = np.zeros(num_epochs)\n",
        "\n",
        "train_network(nn, optimizer, loss, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, num_epochs, train_losses, test_losses)"
      ],
      "metadata": {
        "id": "ZGSr7No8WP_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(1, num_epochs + 1), train_losses, color='orange', label=\"Train Loss\")\n",
        "plt.plot(np.arange(1, num_epochs + 1), test_losses, color='r', label=\"Test Loss\")\n",
        "plt.title(\"Train and Test Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.grid(True, color='lightgray', linestyle='--', linewidth=0.5)\n",
        "plt.gca().spines[['right', 'top']].set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ZOACl4dIMYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the accuracy\n",
        "predictions_train = []\n",
        "predictions_test =  []\n",
        "predictions_val = []\n",
        "with torch.no_grad():\n",
        "    predictions_train = nn(X_train_tensor)\n",
        "    predictions_test = nn(X_test_tensor)\n",
        "    predictions_val = nn(X_val_tensor)\n",
        "\n",
        "nn_train_accuracy = get_accuracy_multiclass(predictions_train, y_train_tensor)\n",
        "nn_val_accuracy = get_accuracy_multiclass(predictions_val, y_val_tensor)\n",
        "nn_test_accuracy = get_accuracy_multiclass(predictions_test, y_test_tensor)\n",
        "\n",
        "\n",
        "numpy_predictions_test = predictions_test.numpy()\n",
        "numpy_predictions_test_binary = []\n",
        "\n",
        "for i in range(len(numpy_predictions_test)):\n",
        "  if numpy_predictions_test[i][0] > numpy_predictions_test[i][1]:\n",
        "    numpy_predictions_test_binary.append(0)\n",
        "  else:\n",
        "    numpy_predictions_test_binary.append(1)\n",
        "\n",
        "nn_stats = precision_recall_fscore_support(y_test, numpy_predictions_test_binary, average='macro')"
      ],
      "metadata": {
        "id": "G19BD5gnIsG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression**"
      ],
      "metadata": {
        "id": "eF4wP5Pg6Q4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize, train, and test linear regression model\n",
        "linearRegression = LinearRegression()\n",
        "linearRegression.fit(X_train, y_train)\n",
        "\n",
        "linear_train_results = linearRegression.predict(X_train)\n",
        "linear_val_results = linearRegression.predict(X_val)\n",
        "linear_test_results = linearRegression.predict(X_test)\n",
        "\n",
        "linear_train_results = np.where(linear_train_results >= 0.5, 1, 0)\n",
        "linear_val_results = np.where(linear_val_results >= 0.5, 1, 0)\n",
        "linear_test_results = np.where(linear_test_results >= 0.5, 1, 0)\n",
        "\n",
        "lr_train_accuracy = accuracy_score(y_train, linear_train_results)\n",
        "lr_test_accuracy = accuracy_score(y_test, linear_test_results)\n",
        "lr_val_accuracy = accuracy_score(y_val, linear_val_results)\n",
        "\n",
        "lr_stats = precision_recall_fscore_support(y_test, linear_test_results, average='macro')"
      ],
      "metadata": {
        "id": "a7j5Aoun6R42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Support Vector Machine**"
      ],
      "metadata": {
        "id": "klJFZrgpZgim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize, train, and test SVM\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "svm_train_results=  svm.predict(X_train)\n",
        "svm_val_results = svm.predict(X_val)\n",
        "svm_test_results = svm.predict(X_test)\n",
        "\n",
        "svm_train_accuracy = accuracy_score(y_train, svm_train_results)\n",
        "svm_test_accuracy = accuracy_score(y_test, svm_test_results)\n",
        "svm_val_accuracy = accuracy_score(y_val, svm_val_results)\n",
        "\n",
        "svm_stats = precision_recall_fscore_support(y_test, svm_test_results, average='macro')\n",
        "\n",
        "print(svm_train_accuracy)\n",
        "print(svm_test_accuracy)\n",
        "print(svm_val_accuracy)"
      ],
      "metadata": {
        "id": "FAUPORd4ZgSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Nearest Neighbors**"
      ],
      "metadata": {
        "id": "CcdelvCcZjw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize, train, and test KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3, p=0.3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "knn_train_results=  knn.predict(X_train)\n",
        "knn_val_results = knn.predict(X_val)\n",
        "knn_test_results = knn.predict(X_test)\n",
        "\n",
        "knn_train_accuracy = accuracy_score(y_train, knn_train_results)\n",
        "knn_test_accuracy = accuracy_score(y_test, knn_test_results)\n",
        "knn_val_accuracy = accuracy_score(y_val, knn_val_results)\n",
        "\n",
        "knn_stats = precision_recall_fscore_support(y_test, knn_test_results, average='macro')"
      ],
      "metadata": {
        "id": "SzsoXIXFZjnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ],
      "metadata": {
        "id": "aZalVz2WYmNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph accuracy results\n",
        "X_graph = [1, 2 , 3, 4, 5]\n",
        "y_val_graph = [xgb_val_accuracy, nn_val_accuracy, lr_val_accuracy, svm_val_accuracy, knn_val_accuracy]\n",
        "y_test_graph = [xgb_test_accuracy, nn_test_accuracy, lr_test_accuracy, svm_test_accuracy, knn_test_accuracy]\n",
        "y_train_graph = [xgb_train_accuracy, nn_train_accuracy, lr_train_accuracy, svm_train_accuracy, knn_train_accuracy]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(X_graph, y_val_graph, marker='^', color='r', label='Validation Accuracy')\n",
        "plt.plot(X_graph, y_test_graph, marker='s', color='orange', label='Test Accuracy')\n",
        "plt.plot(X_graph, y_train_graph, marker='o', color='y', label='Training Accuracy')\n",
        "plt.xticks(X_graph, ['XGBoost', 'Neural Network', 'Linear Regression', 'Support Vector Machine', 'K-Nearest Neighbors'])\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training, Test, and Validation Accuracy for Different Models')\n",
        "plt.legend()\n",
        "plt.grid(True, color='lightgray', linestyle='--', linewidth=0.5)\n",
        "plt.gca().spines[['right', 'top']].set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J-_zK8leYlmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print metric results\n",
        "print(\"{:^30}{:^10}{:^10}{:^10}{:^10}\".format(\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"))\n",
        "print(\"-\"*70)\n",
        "print(\"{:^30}{:^10.2f}{:^10.2f}{:^10.2f}{:^10.2f}\".format(\"XGBoost\", xgb_test_accuracy*100, xgb_stats[0]*100, xgb_stats[1]*100, xgb_stats[2]*100))\n",
        "print(\"{:^30}{:^10.2f}{:^10.2f}{:^10.2f}{:^10.2f}\".format(\"Neural Network\", nn_test_accuracy*100, nn_stats[0]*100, nn_stats[1]*100, nn_stats[2]*100))\n",
        "print(\"{:^30}{:^10.2f}{:^10.2f}{:^10.2f}{:^10.2f}\".format(\"Linear Regression\", lr_test_accuracy*100, lr_stats[0]*100, lr_stats[1]*100, lr_stats[2]*100))\n",
        "print(\"{:^30}{:^10.2f}{:^10.2f}{:^10.2f}{:^10.2f}\".format(\"SVM\", svm_test_accuracy*100, svm_stats[0]*100, svm_stats[1]*100, svm_stats[2]*100))\n",
        "print(\"{:^30}{:^10.2f}{:^10.2f}{:^10.2f}{:^10.2f}\".format(\"K-NN\", knn_test_accuracy*100, knn_stats[0]*100, knn_stats[1]*100, knn_stats[2]*100))"
      ],
      "metadata": {
        "id": "QVLAS5xSTFzx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}